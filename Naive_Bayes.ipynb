{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier :3\n",
    "Other types of classification problems with C different labels\n",
    "+ Instead of finding out exactly label of each data point. We can find out $ Probility$ that outcome falls into each label\n",
    "$p(y=c | x) $ abbriviated as $p(c|x)$\n",
    "+ This expression is understood probility that outcome label is $C$ know income is vector $x$   \n",
    "+ If it is calculated this expression , it can help us determine label of each data point by picking out label has the highest probility falling into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ c = \\argmin_{c ∈ {1,...,C}} p(c|x) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In general , it is difficult to directly calculate $p(c|x)$ . Instead  , the usal Bayes rule used : $p(c|x) = \\frac{p(x|c)p(c)}{p(x)} = p(x|c)p(c)$\n",
    "+ We can drop $p(c)$ because it doesnt depend on $c$\n",
    "+ If training set is large . $p(c)$ can determine by MLE method  $p(c) = \\frac{numbers points belonging to c label}{N}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $p(x|c)$ this component  is often difficult to calculate because $x$ is a high-dimensional random variable\n",
    "+ Simplicity Calculating : It is often assumed that the components of the random variable x are independent  of each other\n",
    "$$p(x|c) = p(x1,x2,x3,....xn) = \\Pi_{i=1}^{d}p(x_{i}|c) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ When d is large and the probilities is small, that expression  is a tiny small. While calculating, error maybe occur.\n",
    "+ To solve this problem, normaly written again by taking the $log$ of the right hand side\n",
    "$$ c = (log(p(c)) + \\sum_{i=1}^{d}log(p(x|c)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commonly used Distribution in NBC :\n",
    "+ Gaussian  naive Bayes\n",
    "+ Multinomial naive Bayes \n",
    "+ Bernoulli Naive Bayes \\\n",
    "=>You can get more info of these on the Internet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Screenshot 2023-10-31 231759.png\" width=\"1000\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For example of Multinomial naive Bayes \n",
    "#Problem :Suppose in the training exercise there are texts d1, d2, d3, d4 as shown in Table Below\n",
    "#Each of these texts belongs to one of two labels: B (North) or N (South). Be authentic\n",
    "#Define label of text d5.\n",
    "Image(url=\"Screenshot 2023-10-31 231759.png\", width=1000, height=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can predict that d5 is labeled North"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ This problem can be solved using NBC using polynomial Naive Bayes\n",
    "or naive Bernoulli Bayes. We will do the first and second examples together \\\n",
    "+ Develop declarative code for both models. Which model is better depends on each problem. \\\n",
    "We can try both to choose the better model.\n",
    "+ Realizing that here there are two labels B and N, we need to find p(B) and p(N) based on\n",
    "frequency of appearance of each label in the training set. We have :\n",
    "$$p(B) = \\frac{3}{4} , p(N) =\\frac{1}{4}$$\n",
    "+ The set of all words in the training set is :\n",
    "V = {hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./Screenshot 2023-11-01 000408.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"./Screenshot 2023-11-01 000408.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrates the training and testing process for this problem when using Multinomial naive Bayes, \\\n",
    "which Laplace softening is used with\n",
    "α = 1. \\\n",
    "Note, the two found values 1.5 × 10−4 and 1.75 × 10−5 are not two the probability to be found is two quantities proportional to those two probabilities. \n",
    "To calculate the instrument , we can do the following : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$p(B|d5) = \\frac{1.5 × 10^{−4}}{\n",
    "1.5 × 10^{−4} + 1.75 × 10^{−5}}\n",
    "≈ 0.8955, \\ p(N|d5) = 1−p(B|d5) ≈ 0.104$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class of d5: B\n",
      "Probability of d6 in each class: [[0.29175335 0.70824665]]\n"
     ]
    }
   ],
   "source": [
    "#With libraries\n",
    "from __future__ import print_function\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "# train data\n",
    "d1 = [2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "d2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "d3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "d4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
    "train_data = np.array([d1, d2, d3, d4])\n",
    "label = np.array([\"B\", \"B\", \"B\", \"N\"])\n",
    "# test data\n",
    "d5 = np.array([[2, 0, 0, 1, 0, 0, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\n",
    "## call MultinomialNB\n",
    "model = MultinomialNB()\n",
    "# training\n",
    "model.fit(train_data, label)\n",
    "# test\n",
    "print(\"Predicting class of d5:\", str(model.predict(d5)[0]))\n",
    "print(\"Probability of d6 in each class:\", model.predict_proba(d6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use naive Bernoulli Bayes, we need to change the feature a bit\n",
    "vector. At this time, other values will not be given because we only care\n",
    "pay attention to whether the word appears in the text or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting class of d5: B\n",
      "Probability of d6 in each class: [[0.16948581 0.83051419]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np\n",
    "# train data\n",
    "d1 = [1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "d2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "d3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "d4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
    "train_data = np.array([d1, d2, d3, d4])\n",
    "label = np.array([\"B\", \"B\", \"B\", \"N\"]) # 0 - B, 1 - N\n",
    "# test data\n",
    "d5 = np.array([[1, 0, 0, 1, 0, 0, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\n",
    "## call MultinomialNB\n",
    "model = BernoulliNB()\n",
    "# training\n",
    "model.fit(train_data, label)\n",
    "# test\n",
    "print(\"Predicting class of d5:\", str(model.predict(d5)[0]))\n",
    "print(\"Probability of d6 in each class:\", model.predict_proba(d6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank for your reading. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
